{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModel, AlbertTokenizerFast, ElectraTokenizerFast\n",
    "\n",
    "from data import SNLIDataset, SNLIBiEncoderBucketingDataset\n",
    "from data.utils import get_data, collate_fn_buckets, collate_fn_biencoder\n",
    "\n",
    "from model import NLIBiEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNLI: 3-way classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, val = get_data('snli_1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['entailment', 'contradiction', 'neutral']\n",
    "NUM_LABELS = len(LABELS)\n",
    "\n",
    "test = test[test.target.isin(set(LABELS))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two women are embracing while holding to go pa...</td>\n",
       "      <td>The sisters are hugging goodbye while holding ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Two women are embracing while holding to go pa...</td>\n",
       "      <td>Two woman are holding packages.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Two women are embracing while holding to go pa...</td>\n",
       "      <td>The men are fighting outside a deli.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two young children in blue jerseys, one with t...</td>\n",
       "      <td>Two kids in numbered jerseys wash their hands.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Two young children in blue jerseys, one with t...</td>\n",
       "      <td>Two kids at a ballgame wash their hands.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  Two women are embracing while holding to go pa...   \n",
       "1  Two women are embracing while holding to go pa...   \n",
       "2  Two women are embracing while holding to go pa...   \n",
       "3  Two young children in blue jerseys, one with t...   \n",
       "4  Two young children in blue jerseys, one with t...   \n",
       "\n",
       "                                           sentence2         target  \n",
       "0  The sisters are hugging goodbye while holding ...        neutral  \n",
       "1                    Two woman are holding packages.     entailment  \n",
       "2               The men are fighting outside a deli.  contradiction  \n",
       "3     Two kids in numbered jerseys wash their hands.     entailment  \n",
       "4           Two kids at a ballgame wash their hands.        neutral  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target2idx = {l: i for i, l in enumerate(LABELS)}\n",
    "test.target = test.target.map(target2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    all_preds, all_true = [], []\n",
    "\n",
    "    i = 0\n",
    "    for batch in tqdm(test_loader):\n",
    "        x = batch[:-1]\n",
    "        y = batch[-1]\n",
    "        all_true.append(y.numpy())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(*x).detach()\n",
    "        \n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        preds = probs.argmax(dim=-1)\n",
    "        all_preds.append(preds.numpy())\n",
    "    \n",
    "    all_true = np.concatenate(all_true)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    \n",
    "    pprint({\n",
    "        'accuracy': accuracy_score(all_true, all_preds),\n",
    "        'f1_macro': f1_score(all_true, all_preds, average='macro'),\n",
    "        'f1_micro': f1_score(all_true, all_preds, average='micro'),\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19684/19684 [00:01<00:00, 11096.44it/s]\n"
     ]
    }
   ],
   "source": [
    "albert_tokenizer = AlbertTokenizerFast.from_pretrained('albert-base-v2')\n",
    "test_dataset = SNLIBiEncoderBucketingDataset(albert_tokenizer, test.sentence1.tolist(), test.sentence2.tolist(), test.target.tolist(), batch_size=1)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "albert_v1 = AutoModel.from_pretrained('albert-base-v2')\n",
    "model_albert_v1 = NLIBiEncoder(albert_v1, NUM_LABELS, lambda x: x.pooler_output)\n",
    "model_albert_v1.load_state_dict(torch.load('albert/v1/albert_snli_best.pt', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9842/9842 [25:43<00:00,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8138589717537086,\n",
      " 'f1_macro': 0.813392961971716,\n",
      " 'f1_micro': 0.8138589717537086}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model_albert_v1, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SNLIDataset(test.sentence1.tolist(), test.sentence2.tolist(), test.target.tolist())\n",
    "collate_fn_biencoder = partial(collate_fn_biencoder, tokenizer=albert_tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn_biencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "albert_v2 = AutoModel.from_pretrained('albert-base-v2')\n",
    "model_albert_v2 = NLIBiEncoder(albert_v2, NUM_LABELS, lambda x: x.pooler_output)\n",
    "model_albert_v2.load_state_dict(torch.load('albert/v2/albert_snli_best.pt', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9842/9842 [24:57<00:00,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8065433854907539,\n",
      " 'f1_macro': 0.8063974009722755,\n",
      " 'f1_micro': 0.8065433854907539}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model_albert_v2, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELECTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19684/19684 [00:01<00:00, 12552.16it/s]\n"
     ]
    }
   ],
   "source": [
    "electra_tokenizer = ElectraTokenizerFast.from_pretrained('google/electra-base-discriminator')\n",
    "test_dataset = SNLIBiEncoderBucketingDataset(electra_tokenizer, test.sentence1.tolist(), test.sentence2.tolist(), test.target.tolist(), batch_size=1)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electra_v1 = AutoModel.from_pretrained('google/electra-base-discriminator')\n",
    "model_electra_v1 = NLIBiEncoder(electra_v1, NUM_LABELS, lambda x: x.last_hidden_state[:, 0, :])\n",
    "model_electra_v1.load_state_dict(torch.load('electra/v1/electra_snli_best.pt', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9842/9842 [27:07<00:00,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8194472668156879,\n",
      " 'f1_macro': 0.8193417460422833,\n",
      " 'f1_micro': 0.8194472668156879}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model_electra_v1, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SNLIDataset(test.sentence1.tolist(), test.sentence2.tolist(), test.target.tolist())\n",
    "collate_fn_biencoder = partial(collate_fn_biencoder, tokenizer=electra_tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn_biencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electra_v2 = AutoModel.from_pretrained('google/electra-base-discriminator')\n",
    "model_electra_v2 = NLIBiEncoder(electra_v2, NUM_LABELS, lambda x: x.last_hidden_state[:, 0, :])\n",
    "model_electra_v2.load_state_dict(torch.load('electra/v2/electra_snli_best.pt', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9842/9842 [23:58<00:00,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.826153220890063,\n",
      " 'f1_macro': 0.8253713781247237,\n",
      " 'f1_micro': 0.826153220890063}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model_electra_v2, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last model (ELECTRA fine-tuned on the SNLI dataset) clearly produced the best results. It is not comparable to SOTA models (~92% accuracy), but that result would probably be achieved if we constructed our feature vector by doing more than just concatenating the encoder's output vectors (as I have later found out, it is common to concatenate not just those vectors, but also their elementwise absolute difference as well as elementwise product: $[u$, $v$, $|u-v|$, $u*v]$) and if we used a larger batch size. One trick to be able to afford a larger batch size is to cache the model's encoder outputs in case of identical premises (most of the examples in the SNLI dataset go in triplets, where the premise is the same)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quora Question Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our model to try and detect paraphrases in the Quora Question Pairs dataset. Hopefully, it is able to produce decent sentence embeddings after being fine-tuned for the NLI task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora = pd.read_csv('quora/train.csv')[:10000]\n",
    "quora.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19413"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = set(quora.question1) | set(quora.question2)\n",
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(sentence, tokenizer, model):\n",
    "    token_ids = electra_tokenizer([sentence], truncation=True, return_tensors='pt').input_ids\n",
    "    with torch.no_grad():\n",
    "        sent_emb = model.encoder(token_ids).last_hidden_state[:, 0, :].detach().squeeze(0).numpy()\n",
    "        \n",
    "    return sent_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19413/19413 [23:44<00:00, 13.63it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = {s: get_sentence_embedding(s, electra_tokenizer, model_electra_v2)\n",
    "             for s in tqdm(questions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings['What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(row):\n",
    "    emb1 = embeddings[row.question1]\n",
    "    emb2 = embeddings[row.question2]\n",
    "    \n",
    "    score = np.dot(emb1 / np.linalg.norm(emb1), emb2 / np.linalg.norm(emb2))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora['score'] = quora.apply(get_score, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.972247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.714898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.663342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.578619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.511743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate     score  \n",
       "0  What is the step by step guide to invest in sh...             0  0.972247  \n",
       "1  What would happen if the Indian government sto...             0  0.714898  \n",
       "2  How can Internet speed be increased by hacking...             0  0.663342  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  0.578619  \n",
       "4            Which fish would survive in salt water?             0  0.511743  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7058667147931963"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(quora.is_duplicate, quora.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without any fine-tuning on this dataset, our model is able to provide a decent ROC-AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
